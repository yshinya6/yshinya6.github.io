---
layout: post
---


<div class="home">
  <div class="site-header-container">
    <div class="scrim">
      <header class="site-header">
        <div class="subimg">
        <img src="assets/me.jpg">
        </div>
        <h3 class="title">{{ site.title }}</h3>
      </header>
    </div>
  </div>
</div>

I am a researcher at [NTT](https://www.rd.ntt/e/cds/) and a Ph.D student at Kyoto University ([Kashima Lab.](http://www.ml.ist.i.kyoto-u.ac.jp/en/)).
My research interests are generative adversarial networks, representation learning, and transfer learning.

# Updates
* **[2023/04/26]** Our paper [Switching One-Versus-the-Rest Loss to Increase the Margin of Logits for Adversarial Robustness](https://arxiv.org/abs/2207.10283) has been accepted to ICML 2023! This paper investigates the cause of the vulnerability of adversarial training methods focusing on the importance of data points in terms of the margin between logits, and proposes switching one-versus-the-rest loss (SOVR), which promotes the margins to be increased. I contributed to composing this paper's Introduction and Experiments as the second author.
* **[2022/09/14]** Our paper [Meta-ticket: Finding optimal subnetworks for few-shot learning within randomly initialized neural networks](https://arxiv.org/abs/2205.15619) has been accepted by NeurIPS 2022. In this paper, we propose a novel meta learning approach, which optimizing edges on neural networks instead of the weight to find a optimal subnetworks for few-shot learning.
* **[2022/07/12]** I have been selected as an outstanding reviewer at ICML 2022, which is top 10% of all reviewers. This was the first reviewer assignment in my career.


# Activities
## Services as a Reviewer
- 2022: ICML, NeurIPS
- 2023: CVPR, PAKDD, ICML, ICCV, NeurIPS

# Biography
### Apr. 2022 - Current
Ph.D student at Dept. of Intelligence Science & Technology, Graduate School of Informatics, Kyoto University

### Apr. 2017 - Current
Researcher at NTT

### Apr. 2015 - Mar. 2017
M.E. from Dept. of Computer Engineering, Graduate School of Engineering, Yokohama National University

### Apr. 2011 - Mar. 2015
B.E. from Dept. of Computer Engineering, Yokohama National University

# Publications
[Google Scholar](https://scholar.google.com/citations?user=_xJYVD0AAAAJ)

[DBLP](https://dblp.org/pid/215/6588.html)
## International Conference
1. S. Kanai, <u>S. Yamaguchi</u>, M. Yamada, H. Takahashi, Y. Ida, 
[**Switching One-Versus-the-Rest Loss to Increase the Margin of Logits for Adversarial Robustness**](https://arxiv.org/abs/2207.10283),  
International Conference on Machine Learning (ICML), 2023.
2. D. Chijiwa, <u>S. Yamaguchi</u>, A. Kumagai, Y. Ida,  
[**Meta-ticket: Finding optimal subnetworks for few-shot learning within randomly initialized neural networks**](https://arxiv.org/abs/2205.15619),  
Neural Information Processing Systems (NeurIPS), 2022.
3. K. Adachi, <u>S. Yamaguchi</u>,  
[**Learning Robust Convolutional Neural Networks with Relevant Feature Focusing via Explanations**](https://arxiv.org/abs/2202.04237),  
IEEE International Conference on Multimedia & Expo (ICME), 2022.
4. D. Chijiwa, <u>S. Yamaguchi</u>, Y. Ida, K. Umakoshi, T. Inoue,  
[**Pruning Randomly Initialized Neural Networks with Iterative Randomization**](https://openreview.net/pdf?id=QCPY2eMXYs),  
Neural Information Processing Systems (NeurIPS, **Spotlight**), 2021. [[arXiv]](https://arxiv.org/abs/2106.09269) [[code]](https://github.com/dchiji-ntt/iterand)
5. <u>S. Yamaguchi</u>, S. Kanai,  
[**F-Drop&Match: GANs with a Dead Zone in the High-Frequency Domain**](https://openaccess.thecvf.com/content/ICCV2021/html/Yamaguchi_F-DropMatch_GANs_With_a_Dead_Zone_in_the_High-Frequency_Domain_ICCV_2021_paper.html),  
International Conference on Computer Vision (ICCV), 2021. [[arXiv]](https://arxiv.org/abs/2106.02343)
6. <u>S. Yamaguchi</u>, S. Kanai, T. Shioda, S. Takeda,  
[**Image Enhanced Rotation Prediction for Self-Supervised Learning**](https://ieeexplore.ieee.org/document/9506132),  
IEEE International Conference on Image Processing (ICIP), 2021. [[arXiv]](https://arxiv.org/abs/1912.11603)
7. S. Kanai, M. Yamada, <u>S. Yamaguchi</u>, H. Takahashi, Y. Ida,   
[**Constraining Logits by Bounded Function for Adversarial Robustness**](https://ieeexplore.ieee.org/document/9533777),  
International Joint Conference on Neural Networks (IJCNN), 2021. [[arXiv]](https://arxiv.org/abs/2010.02558)
8. <u>S. Yamaguchi</u>, S. Kanai, T. Eda,  
[**Effective Data Augmentation with Multi-Domain Learning GANs**](https://ojs.aaai.org/index.php/AAAI/article/view/6131),  
AAAI Conference on Artificial Intelligence (AAAI), 2020. [[arXiv]](https://arxiv.org/abs/1912.11597)
9. <u>S. Yamaguchi</u>, K. Kuramitsu,  
[**A Fusion Techniques of Schema and Syntax Rules for Validating Open Data**](https://link.springer.com/chapter/10.1007/978-3-319-56660-3_37),  
Asian Conference on Intelligent Information and Database Systems (ACIIDS), 2017

## Preprints
1. K. Adachi, <u>S. Yamaguchi</u>, A. Kumagai,  
[**Covariance-aware Feature Alignment with Pre-computed Source Statistics for Test-time Adaptation**](https://arxiv.org/abs/2204.13263),  
arXiv, 2022.
2. <u>S. Yamaguchi</u>, S. Kanai, A. Kumagai, D. Chijiwa, H. Kashima,  
[**Transfer Learning with Pre-trained Conditional Generative Models**](https://arxiv.org/abs/2204.12833),  
arXiv, 2022.
3. <u>S. Yamaguchi</u>, S. Kanai, T. Shioda, S. Takeda,  
[**Multiple pretext-task for self-supervised learning via mixing multiple image transformations**](https://arxiv.org/abs/1912.11603v1),  
arXiv, 2019.
4. K. Kuramitsu, <u>S. Yamaguchi</u>,  
[**XML Schema Validation using Parsing Expression Grammars**](https://peerj.com/preprints/1503.pdf),  
PeerJ PrePrints, 2015

# Honors
* Outstanding Reviewer: ICML 2022

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-GLL931QDKD"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-GLL931QDKD');
</script>
